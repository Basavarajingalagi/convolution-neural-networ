{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcPShRxLdQ0",
        "colab_type": "text"
      },
      "source": [
        "I have imported the necessary library to perform the computation in this ipython notebook. It uses keras api built on top of tensorflow 2.o"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTh_ubHR9cKj",
        "colab_type": "code",
        "outputId": "9ff4b0f5-5d32-4992-a024-4a498cb04e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras import layers, models, optimizers\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n56fgnygLOw4",
        "colab_type": "text"
      },
      "source": [
        "I have used the following code snippet to mount drive to the collab notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW5Q7fG_ABas",
        "colab_type": "code",
        "outputId": "30969e1a-9b56-4af0-b150-3c2ee154babd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmWLqJJRMaT7",
        "colab_type": "text"
      },
      "source": [
        "the following code does image augmentation. This prevents our model from overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nk1GayTAKJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
        "                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
        "                                   horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIF0w4S0MUT4",
        "colab_type": "text"
      },
      "source": [
        "i have used .flow directory from keras this helps in reading the train file into respective classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVsYw4bbATWD",
        "colab_type": "code",
        "outputId": "dd88751e-027b-452c-9041-a55ce2e3d379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/Colab Notebooks/Dataset/train',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=10,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 440 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDFxtfO2M4Ew",
        "colab_type": "text"
      },
      "source": [
        "I have used input shape as 150,150 into 3 channels as size of the image. Since 800*800 original time would take lot of time to train on epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDMXeof4AXo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = 150,150,3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msg7ElXxNYKr",
        "colab_type": "text"
      },
      "source": [
        "This is the model building part.\n",
        "here i have used conv2D for feature extraction of 4 convolution layers with kernel size of 3 * 3 and activation function used was 'relu'\n",
        "i have done maxpooling of size 2,2 for each convolutinal layer. this extracts the maximum featurs into 2 * 2 matrix and also reduces size of orignal matrix.\n",
        "i have used 3 dense layers for connection before that i flatened convolutional layer using flatten function\n",
        "later i used dropout to prevent further overfitting at densely fully connected neural network.\n",
        "\n",
        "**And note : i have trained this model for only 52 epochs u can also play around with this value. Earlier i tried on 100 epochs the training accuracy came around 96.52% . That would consume a lot of training time and computational power. And there was not much significant improvement after 50 epochs. So i have limited it to just 52 epochs. But u can always increase this value for better accuracy if we have more computational power.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ylBe_MzApof",
        "colab_type": "code",
        "outputId": "e00145bf-c996-42ab-d18f-878945182d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', \n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "history = model.fit_generator(train_generator, steps_per_epoch=44, epochs=52,\n",
        "                              verbose=1) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0801 16:40:36.517597 140473416095616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0801 16:40:36.561264 140473416095616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0801 16:40:36.569652 140473416095616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0801 16:40:36.613060 140473416095616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0801 16:40:36.688505 140473416095616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0801 16:40:36.702425 140473416095616 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0801 16:40:36.778693 140473416095616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0801 16:40:36.789824 140473416095616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0801 16:40:36.925026 140473416095616 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/52\n",
            "44/44 [==============================] - 115s 3s/step - loss: 1.3267 - acc: 0.3432\n",
            "Epoch 2/52\n",
            "44/44 [==============================] - 24s 545ms/step - loss: 1.0542 - acc: 0.4909\n",
            "Epoch 3/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.8984 - acc: 0.5523\n",
            "Epoch 4/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.8561 - acc: 0.5977\n",
            "Epoch 5/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.7353 - acc: 0.6636\n",
            "Epoch 6/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.7064 - acc: 0.6864\n",
            "Epoch 7/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.6257 - acc: 0.7523\n",
            "Epoch 8/52\n",
            "44/44 [==============================] - 23s 517ms/step - loss: 0.5661 - acc: 0.7864\n",
            "Epoch 9/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.5280 - acc: 0.7818\n",
            "Epoch 10/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.5735 - acc: 0.7955\n",
            "Epoch 11/52\n",
            "44/44 [==============================] - 23s 523ms/step - loss: 0.4750 - acc: 0.8432\n",
            "Epoch 12/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.4054 - acc: 0.8659\n",
            "Epoch 13/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.3992 - acc: 0.8545\n",
            "Epoch 14/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.4107 - acc: 0.8432\n",
            "Epoch 15/52\n",
            "44/44 [==============================] - 23s 515ms/step - loss: 0.3791 - acc: 0.8705\n",
            "Epoch 16/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.3525 - acc: 0.8659\n",
            "Epoch 17/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.3457 - acc: 0.8818\n",
            "Epoch 18/52\n",
            "44/44 [==============================] - 23s 517ms/step - loss: 0.3347 - acc: 0.8795\n",
            "Epoch 19/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.2803 - acc: 0.9250\n",
            "Epoch 20/52\n",
            "44/44 [==============================] - 23s 520ms/step - loss: 0.3105 - acc: 0.8909\n",
            "Epoch 21/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.2581 - acc: 0.8955\n",
            "Epoch 22/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.2740 - acc: 0.9068\n",
            "Epoch 23/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.2766 - acc: 0.8955\n",
            "Epoch 24/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.2791 - acc: 0.9091\n",
            "Epoch 25/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.2597 - acc: 0.9091\n",
            "Epoch 26/52\n",
            "44/44 [==============================] - 23s 520ms/step - loss: 0.2192 - acc: 0.9159\n",
            "Epoch 27/52\n",
            "44/44 [==============================] - 23s 517ms/step - loss: 0.2090 - acc: 0.9205\n",
            "Epoch 28/52\n",
            "44/44 [==============================] - 23s 517ms/step - loss: 0.1938 - acc: 0.9364\n",
            "Epoch 29/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.1848 - acc: 0.9205\n",
            "Epoch 30/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.1702 - acc: 0.9318\n",
            "Epoch 31/52\n",
            "44/44 [==============================] - 23s 521ms/step - loss: 0.1957 - acc: 0.9250\n",
            "Epoch 32/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.2577 - acc: 0.9159\n",
            "Epoch 33/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.2565 - acc: 0.9159\n",
            "Epoch 34/52\n",
            "44/44 [==============================] - 23s 520ms/step - loss: 0.2237 - acc: 0.9273\n",
            "Epoch 35/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.1616 - acc: 0.9432\n",
            "Epoch 36/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.2532 - acc: 0.9295\n",
            "Epoch 37/52\n",
            "44/44 [==============================] - 23s 520ms/step - loss: 0.1689 - acc: 0.9500\n",
            "Epoch 38/52\n",
            "44/44 [==============================] - 23s 521ms/step - loss: 0.1597 - acc: 0.9432\n",
            "Epoch 39/52\n",
            "44/44 [==============================] - 23s 521ms/step - loss: 0.2156 - acc: 0.9205\n",
            "Epoch 40/52\n",
            "44/44 [==============================] - 23s 517ms/step - loss: 0.1238 - acc: 0.9500\n",
            "Epoch 41/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.2103 - acc: 0.9455\n",
            "Epoch 42/52\n",
            "44/44 [==============================] - 23s 520ms/step - loss: 0.1537 - acc: 0.9500\n",
            "Epoch 43/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.1110 - acc: 0.9568\n",
            "Epoch 44/52\n",
            "44/44 [==============================] - 23s 520ms/step - loss: 0.2113 - acc: 0.9409\n",
            "Epoch 45/52\n",
            "44/44 [==============================] - 23s 516ms/step - loss: 0.1281 - acc: 0.9523\n",
            "Epoch 46/52\n",
            "44/44 [==============================] - 23s 516ms/step - loss: 0.1689 - acc: 0.9318\n",
            "Epoch 47/52\n",
            "44/44 [==============================] - 23s 517ms/step - loss: 0.1232 - acc: 0.9591\n",
            "Epoch 48/52\n",
            "44/44 [==============================] - 23s 517ms/step - loss: 0.1957 - acc: 0.9409\n",
            "Epoch 49/52\n",
            "44/44 [==============================] - 23s 518ms/step - loss: 0.1326 - acc: 0.9545\n",
            "Epoch 50/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.1493 - acc: 0.9364\n",
            "Epoch 51/52\n",
            "44/44 [==============================] - 23s 519ms/step - loss: 0.1783 - acc: 0.9432\n",
            "Epoch 52/52\n",
            "44/44 [==============================] - 23s 517ms/step - loss: 0.1566 - acc: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkF03Yz-Qerd",
        "colab_type": "text"
      },
      "source": [
        "Its always a good practice to save our model after training.\n",
        "so i have imported load_model from keras.model and used model.save() function to save it.and load_model() to reload the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57dj0dXjAsND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrjpWGEgAzZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('convo.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFLgCramA2lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model  = load_model('convo.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFikVRZGRWmy",
        "colab_type": "text"
      },
      "source": [
        "I have imported the globe to access the path directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHLeE10fA-DI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from keras.preprocessing.image import load_img, img_to_array, array_to_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fihKEzztRcVp",
        "colab_type": "text"
      },
      "source": [
        "Here i have opened the test files using glob.function and converted them into the numpy array and rescaled them to predict its classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYKGdKfTBNea",
        "colab_type": "code",
        "outputId": "55ecba00-6479-4037-a716-9e146bd7b9c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "IMG_DIM = (150, 150)\n",
        "\n",
        "test_files = glob.glob('/content/drive/My Drive/Colab Notebooks/Dataset/test/*')\n",
        "test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in test_files]\n",
        "test_imgs = np.array(test_imgs)\n",
        "\n",
        "test_imgs_scaled = test_imgs.astype('float32')\n",
        "test_imgs_scaled /= 255\n",
        "\n",
        "print('Test dataset shape:', test_imgs.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test dataset shape: (30, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7qVZL3USCfb",
        "colab_type": "text"
      },
      "source": [
        "This is the predict method used for predicting the class of image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiuO6AVRBS82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict_classes(test_imgs_scaled, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvQHPiCTKq6f",
        "colab_type": "text"
      },
      "source": [
        "here i have printed the class of every 30 image that was predicted by my model.\n",
        "\n",
        "**0 represents category 1**\n",
        "\n",
        "**1 represents category 2**\n",
        "\n",
        "**2 represents category 3**\n",
        "\n",
        "**3 represents category 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oQ1r_CXIwT9",
        "colab_type": "code",
        "outputId": "4cebbb00-180c-47c7-e3a5-df830847e875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(prediction[1:29])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 2 2 1 2 3 3 2 0 2 0 0 2 2 2 2 2 1 1 1 1 1 3 1 1 3]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}